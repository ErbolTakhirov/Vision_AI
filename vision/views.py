from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.views import View
from .yolo import model
import cv2
import numpy as np
from PIL import Image
import io

# –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
CLASS_NAMES_RU = {
    'person': '—á–µ–ª–æ–≤–µ–∫',
    'bicycle': '–≤–µ–ª–æ—Å–∏–ø–µ–¥',
    'car': '–∞–≤—Ç–æ–º–æ–±–∏–ª—å',
    'motorcycle': '–º–æ—Ç–æ—Ü–∏–∫–ª',
    'airplane': '—Å–∞–º–æ–ª–µ—Ç',
    'bus': '–∞–≤—Ç–æ–±—É—Å',
    'train': '–ø–æ–µ–∑–¥',
    'truck': '–≥—Ä—É–∑–æ–≤–∏–∫',
    'boat': '–ª–æ–¥–∫–∞',
    'traffic light': '—Å–≤–µ—Ç–æ—Ñ–æ—Ä',
    'fire hydrant': '–ø–æ–∂–∞—Ä–Ω—ã–π –≥–∏–¥—Ä–∞–Ω—Ç',
    'stop sign': '–∑–Ω–∞–∫ —Å—Ç–æ–ø',
    'parking meter': '–ø–∞—Ä–≤–æ–∫–æ—á–Ω—ã–π –∞–≤—Ç–æ–º–∞—Ç',
    'bench': '—Å–∫–∞–º–µ–π–∫–∞',
    'bird': '–ø—Ç–∏—Ü–∞',
    'cat': '–∫–æ—à–∫–∞',
    'dog': '—Å–æ–±–∞–∫–∞',
    'horse': '–ª–æ—à–∞–¥—å',
    'sheep': '–æ–≤—Ü–∞',
    'cow': '–∫–æ—Ä–æ–≤–∞',
    'elephant': '—Å–ª–æ–Ω',
    'bear': '–º–µ–¥–≤–µ–¥—å',
    'zebra': '–∑–µ–±—Ä–∞',
    'giraffe': '–∂–∏—Ä–∞—Ñ',
    'backpack': '—Ä—é–∫–∑–∞–∫',
    'umbrella': '–∑–æ–Ω—Ç–∏–∫',
    'handbag': '—Å—É–º–∫–∞',
    'tie': '–≥–∞–ª—Å—Ç—É–∫',
    'suitcase': '—á–µ–º–æ–¥–∞–Ω',
    'frisbee': '—Ñ—Ä–∏—Å–±–∏',
    'skis': '–ª—ã–∂–∏',
    'snowboard': '—Å–Ω–æ—É–±–æ—Ä–¥',
    'sports ball': '–º—è—á',
    'kite': '–≤–æ–∑–¥—É—à–Ω—ã–π –∑–º–µ–π',
    'baseball bat': '–±–µ–π—Å–±–æ–ª—å–Ω–∞—è –±–∏—Ç–∞',
    'baseball glove': '–±–µ–π—Å–±–æ–ª—å–Ω–∞—è –ø–µ—Ä—á–∞—Ç–∫–∞',
    'skateboard': '—Å–∫–µ–π—Ç–±–æ—Ä–¥',
    'surfboard': '—Å–µ—Ä—Ñ–±–æ—Ä–¥',
    'tennis racket': '—Ç–µ–Ω–Ω–∏—Å–Ω–∞—è —Ä–∞–∫–µ—Ç–∫–∞',
    'bottle': '–±—É—Ç—ã–ª–∫–∞',
    'wine glass': '–±–æ–∫–∞–ª –≤–∏–Ω–∞',
    'cup': '—á–∞—à–∫–∞',
    'fork': '–≤–∏–ª–∫–∞',
    'knife': '–Ω–æ–∂',
    'spoon': '–ª–æ–∂–∫–∞',
    'bowl': '–º–∏—Å–∫–∞',
    'banana': '–±–∞–Ω–∞–Ω',
    'apple': '—è–±–ª–æ–∫–æ',
    'sandwich': '—Å—ç–Ω–¥–≤–∏—á',
    'orange': '–∞–ø–µ–ª—å—Å–∏–Ω',
    'broccoli': '–±—Ä–æ–∫–∫–æ–ª–∏',
    'carrot': '–º–æ—Ä–∫–æ–≤—å',
    'hot dog': '—Ö–æ—Ç-–¥–æ–≥',
    'pizza': '–ø–∏—Ü—Ü–∞',
    'donut': '–ø–æ–Ω—á–∏–∫',
    'cake': '—Ç–æ—Ä—Ç',
    'chair': '—Å—Ç—É–ª',
    'couch': '–¥–∏–≤–∞–Ω',
    'potted plant': '—Ä–∞—Å—Ç–µ–Ω–∏–µ –≤ –≥–æ—Ä—à–∫–µ',
    'bed': '–∫—Ä–æ–≤–∞—Ç—å',
    'dining table': '–æ–±–µ–¥–µ–Ω–Ω—ã–π —Å—Ç–æ–ª',
    'toilet': '—Ç—É–∞–ª–µ—Ç',
    'tv': '—Ç–µ–ª–µ–≤–∏–∑–æ—Ä',
    'laptop': '–Ω–æ—É—Ç–±—É–∫',
    'mouse': '–º—ã—à—å',
    'remote': '–ø—É–ª—å—Ç',
    'keyboard': '–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞',
    'cell phone': '—Ç–µ–ª–µ—Ñ–æ–Ω',
    'microwave': '–º–∏–∫—Ä–æ–≤–æ–ª–Ω–æ–≤–∫–∞',
    'oven': '–ø–µ—á—å',
    'toaster': '—Ç–æ—Å—Ç–µ—Ä',
    'sink': '—Ä–∞–∫–æ–≤–∏–Ω–∞',
    'refrigerator': '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫',
    'book': '–∫–Ω–∏–≥–∞',
    'clock': '—á–∞—Å—ã',
    'vase': '–≤–∞–∑–∞',
    'scissors': '–Ω–æ–∂–Ω–∏—Ü—ã',
    'teddy bear': '–ø–ª—é—à–µ–≤—ã–π –º–∏—à–∫–∞',
    'hair drier': '—Ñ–µ–Ω',
    'toothbrush': '–∑—É–±–Ω–∞—è —â–µ—Ç–∫–∞'
}

@method_decorator(csrf_exempt, name='dispatch')
class DetectAPIView(View):
    def post(self, request, *args, **kwargs):
        if 'image' not in request.FILES:
            return JsonResponse({'message': '–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'}, status=400)

        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_file = request.FILES['image']
        image_bytes = image_file.read()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ OpenCV —Ñ–æ—Ä–º–∞—Ç
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

        if img is None:
            return JsonResponse({'message': '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'}, status=400)

        # Preprocessing –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        # 1. Resize –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        max_dimension = 1280
        h, w = img.shape[:2]
        if max(h, w) > max_dimension:
            scale = max_dimension / max(h, w)
            img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)
        
        # 2. –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ (CLAHE)
        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        img = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2BGR)

        # –î–µ—Ç–µ–∫—Ü–∏—è (–ø–æ–Ω–∏–∂–∞–µ–º confidence –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è)
        results = model.predict(img, conf=0.3, iou=0.45)
        
        detected_objects = []
        for result in results:
            for box in result.boxes:
                class_id = int(box.cls[0])
                class_name = model.names[class_id]
                ru_name = CLASS_NAMES_RU.get(class_name, class_name)
                if ru_name not in detected_objects:
                    detected_objects.append(ru_name)

        if not detected_objects:
            message = "–ü—É—Ç—å —Å–≤–æ–±–æ–¥–µ–Ω"
        else:
            message = "–í–ø–µ—Ä–µ–¥–∏: " + ", ".join(detected_objects)

        return JsonResponse({'message': message})


from .services import speech_to_text, analyze_image_local, generate_ai_response_async, text_to_speech_async, read_text_local, detect_objects_local
from .models import VisionUser
import base64
import json
from asgiref.sync import sync_to_async

@method_decorator(csrf_exempt, name='dispatch')
class SmartAnalyzeView(View):
    async def post(self, request, *args, **kwargs):
        import asyncio
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        user = None
        if request.user.is_authenticated:
            user = request.user
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤
            if not await sync_to_async(user.can_make_request)():
                return JsonResponse({
                    'error': 'Daily limit reached',
                    'subscription_type': user.subscription_type,
                    'upgrade_message': 'Upgrade to Premium for unlimited requests'
                }, status=429)
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        image_file = request.FILES.get('image')
        audio_file = request.FILES.get('audio')
        text_input = request.POST.get('text', '')
        user_id = request.POST.get('user_id', 'anonymous')
        mode = request.POST.get('mode', 'chat') # 'chat' or 'navigator'

        # 3. –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Telegram)
        user_tuple = await sync_to_async(VisionUser.objects.get_or_create)(telegram_id=user_id)
        vision_user = user_tuple[0]

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞—Å–∫–æ–≤
        stt_task = None
        vision_task = None
        image_bytes = None

        # –ó–∞–ø—É—Å–∫–∞–µ–º STT
        if audio_file:
            # –í–∞–∂–Ω–æ: –µ—Å–ª–∏ audio_file —ç—Ç–æ InMemoryUploadedFile, –ø–µ—Ä–µ–¥–∞—á–∞ –µ–≥–æ –≤ –¥—Ä—É–≥–æ–π –ø–æ—Ç–æ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å tricky,
            # –Ω–æ faster_whisper –æ–±—ã—á–Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∏–ª–∏ file-like.
            # –î–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ —á–∏—Ç–∞–µ–º –≤ BytesIO –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø—É—Ç—å
            stt_task = sync_to_async(speech_to_text)(audio_file)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Resize)
        if image_file:
            image_bytes = image_file.read()
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –ü–ï–†–ï–î –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ –º–æ–¥–µ–ª–∏ (—Å–Ω–∏–∂–∞–µ–º –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ BLIP/OCR)
            # –°–¥–µ–ª–∞–µ–º resize —Ç—É—Ç, –≤ –ø–∞–º—è—Ç–∏
            def optimize_image(img_data):
                nparr = np.frombuffer(img_data, np.uint8)
                img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                if img is None: return img_data
                
                # Max dimension 640 for speed
                max_dim = 640
                h, w = img.shape[:2]
                if max(h, w) > max_dim:
                    scale = max_dim / max(h, w)
                    img = cv2.resize(img, (int(w * scale), int(h * scale)), interpolation=cv2.INTER_AREA)
                    # Encode back to bytes
                    _, encoded_img = cv2.imencode('.jpg', img, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
                    return encoded_img.tobytes()
                return img_data

            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –∏ Vision –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            # –ù–æ Vision —Ç—Ä–µ–±—É–µ—Ç –±–∞–π—Ç—ã. –õ—É—á—à–µ —Å–Ω–∞—á–∞–ª–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å (–±—ã—Å—Ç—Ä–æ), –ø–æ—Ç–æ–º Vision.
            # optimize_image - CPU bound, sync.
            image_bytes = await sync_to_async(optimize_image)(image_bytes)

            if mode == 'navigator':
                 # Fast YOLO only
                 # –ú—ã –º–æ–∂–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ —Å—Ä–∞–∑—É
                 vision_task = sync_to_async(detect_objects_local)(image_bytes)
            else:
                 # BLIP
                 vision_task = sync_to_async(analyze_image_local)(image_bytes)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ STT –∏ Vision
        tasks = []
        if stt_task: tasks.append(stt_task) # index 0 if exists
        if vision_task: tasks.append(vision_task) # index 0 or 1

        results = await asyncio.gather(*tasks)

        # –†–∞–∑–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        transcript = None
        visual_result = None
        
        current_res_idx = 0
        if stt_task:
            transcript = results[current_res_idx]
            print(f"üé§ DEBUG TRANCRIPT: '{transcript}' (Type: {type(transcript)})")
            current_res_idx += 1
        if vision_task:
            visual_result = results[current_res_idx]
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
        if transcript:
            text_input = f"{text_input} {transcript}".strip()

        # –ï—Å–ª–∏ —Ä–µ–∂–∏–º –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç
        if mode == 'navigator':
            objects = visual_result if visual_result else []
            if objects:
                 response_text = ", ".join(objects)
            else:
                 response_text = ""
            return JsonResponse({'message': response_text, 'audio': None})

        # –†–µ–∂–∏–º —á–∞—Ç–∞
        visual_description = visual_result
        ocr_text = None

        # –¢–µ–ø–µ—Ä—å, –∏–º–µ—è –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç, —Ä–µ—à–∞–µ–º –ø—Ä–æ OCR
        # OCR –≤—Å–µ –µ—â–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–æ–π, –Ω–æ –æ–Ω–∞ –Ω—É–∂–Ω–∞ —Ç–æ–ª—å–∫–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        if image_bytes and any(w in text_input.lower() for w in ['—á–∏—Ç–∞–π', '–ø—Ä–æ—á—Ç–∏', '—Ç–µ–∫—Å—Ç', '–Ω–∞–ø–∏—Å–∞–Ω–æ', '—Ü–∏—Ñ—Ä—ã']):
             ocr_text = await sync_to_async(read_text_local)(image_bytes)

        if not text_input:
             # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞ -> "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ?"
             if visual_description:
                 text_input = "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ?"
             else:
                 return JsonResponse({'message': '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∑–∞–ø—Ä–æ—Å.', 'audio': None})

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        if vision_user:
            await sync_to_async(vision_user.add_message)("user", text_input)

        # 5. LLM - –ø–µ—Ä–µ–¥–∞–µ–º vision_user —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        response_text = await generate_ai_response_async(
            text_input, 
            visual_context=visual_description, 
            user_obj=vision_user if vision_user else None,
            ocr_context=ocr_text
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
        if vision_user:
            await sync_to_async(vision_user.add_message)("assistant", response_text)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        if user:
            await sync_to_async(user.increment_request_count)()

        # 6. TTS
        audio_content = await text_to_speech_async(response_text)
        audio_b64 = None
        if audio_content:
            audio_b64 = base64.b64encode(audio_content).decode('utf-8')

        return JsonResponse({
            'message': response_text,
            'audio': audio_b64,
            'debug_vision': visual_description
        })

def index(request):
    from django.shortcuts import render
    return render(request, 'index.html')


@method_decorator(csrf_exempt, name='dispatch')
class NavigationView(View):
    """
    Endpoint –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –∑–∞–ø—Ä–æ—Å —Ç–∏–ø–∞ "–∫–∞–∫ –¥–æ–π—Ç–∏ –¥–æ –¢—É—Ä—É—Å–±–µ–∫–æ–≤–∞ 109"
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏.
    """
    async def post(self, request, *args, **kwargs):
        audio_file = request.FILES.get('audio')
        text_input = request.POST.get('text', '')
        user_id = request.POST.get('user_id', 'anonymous')
        current_lat = request.POST.get('current_lat')
        current_lon = request.POST.get('current_lon')
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_tuple = await sync_to_async(VisionUser.objects.get_or_create)(telegram_id=user_id)
        user = user_tuple[0]
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ
        if audio_file:
            transcript = await sync_to_async(speech_to_text)(audio_file)
            if transcript:
                text_input = f"{text_input} {transcript}".strip()
        
        if not text_input:
            return JsonResponse({'error': 'No input provided'}, status=400)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–¥—Ä–µ—Å–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        destination = await self._extract_destination(text_input)
        
        if not destination:
            response_text = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ —Å–º–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–¥—Ä–µ—Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–∞–∑–∞—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä: '–ö–∞–∫ –¥–æ–π—Ç–∏ –¥–æ —É–ª–∏—Ü—ã –¢—É—Ä—É—Å–±–µ–∫–æ–≤–∞, –¥–æ–º 109'"
            audio_content = await text_to_speech_async(response_text)
            audio_b64 = base64.b64encode(audio_content).decode('utf-8') if audio_content else None
            return JsonResponse({
                'message': response_text,
                'audio': audio_b64,
                'destination': None
            })
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–¥—Ä–µ—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
        # –ö–ª–∏–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç NavigationService –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞
        response_text = f"–°—Ç—Ä–æ—é –º–∞—Ä—à—Ä—É—Ç –¥–æ {destination}. –ü–æ–¥–æ–∂–¥–∏—Ç–µ..."
        audio_content = await text_to_speech_async(response_text)
        audio_b64 = base64.b64encode(audio_content).decode('utf-8') if audio_content else None
        
        return JsonResponse({
            'message': response_text,
            'audio': audio_b64,
            'destination': destination,
            'action': 'build_route'
        })
    
    async def _extract_destination(self, text):
        """
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç AI –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–¥—Ä–µ—Å–∞ –∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞.
        """
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            # Fallback: –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥
            return self._simple_address_extraction(text)
        
        base_url = "https://api.deepseek.com"
        model_name = "deepseek-chat"
        if api_key.startswith("sk-or-v1"):
            base_url = "https://openrouter.ai/api/v1"
            model_name = "deepseek/deepseek-chat"
        
        from openai import AsyncOpenAI
        client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        
        try:
            response = await client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–¥—Ä–µ—Å–æ–≤. –ò–∑–≤–ª–µ–∫–∏ –∞–¥—Ä–µ—Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∞–¥—Ä–µ—Å, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –∞–¥—Ä–µ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–µ—Ä–Ω–∏ 'NOT_FOUND'."
                    },
                    {
                        "role": "user",
                        "content": f"–ó–∞–ø—Ä–æ—Å: {text}"
                    }
                ],
                max_tokens=100
            )
            
            result = response.choices[0].message.content.strip()
            if result == 'NOT_FOUND' or not result:
                return None
            return result
        except Exception as e:
            logger.error(f"AI address extraction error: {e}")
            return self._simple_address_extraction(text)
    
    def _simple_address_extraction(self, text):
        """
        –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.
        """
        import re
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–¥—Ä–µ—Å–æ–≤
        patterns = [
            r'–¥–æ\s+(.+?)(?:\s+–¥–æ–º\s+\d+|\s+\d+)?$',
            r'–Ω–∞\s+(.+?)(?:\s+–¥–æ–º\s+\d+|\s+\d+)?$',
            r'—É–ª–∏—Ü[–∞—ã]\s+(.+?)(?:\s+–¥–æ–º\s+\d+|\s+\d+)?$',
        ]
        
        text_lower = text.lower()
        for pattern in patterns:
            match = re.search(pattern, text_lower)
            if match:
                return match.group(1).strip()
        
        return None
